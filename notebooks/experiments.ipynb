{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exprel.dataset.semeval_dataset import SemevalDataset\n",
    "import exprel.utils\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SemevalDataset(\"/home/kovacs/projects/exp-relation-extraction/data/semeval_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_graphs(\"pickle.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_versus_rest = data.one_versus_rest(df, \"Entity-Destination(e1,e2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_versus_rest.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = one_versus_rest.groupby(\"label\").size().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ids = pd.to_numeric(one_versus_rest.sen_id).tolist()\n",
    "sentences = one_versus_rest.sentence.tolist()\n",
    "labels = one_versus_rest.label_id.tolist()\n",
    "postprocessed_graphs = one_versus_rest.graph.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exprel.feature_extractor.extract import FeatureExtractor\n",
    "from exprel.models.model import GraphModel\n",
    "\n",
    "extractor = FeatureExtractor()\n",
    "model = GraphModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for ind, graph, label in tqdm(zip(ids, postprocessed_graphs, labels)):\n",
    "    model.featurize_sen_graph(ind, graph, label, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_graphs = model.get_feature_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.select_n_best_from_each_class(400, feature_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_versus_rest.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = model.get_x_y(one_versus_rest.label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "tr_data,tst_data,tr_labels,tst_labels = split(X,Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(tr_data, tr_labels)\n",
    "#clf = DecisionTreeClassifier(random_state=0, max_depth=4).fit(tr_data, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "keys = model.label_vocab.word_to_id.keys()\n",
    "labels_to_result = {}\n",
    "lr_pred = clf.predict(tst_data)\n",
    "prf = precision_recall_fscore_support(tst_labels, lr_pred, average=None)\n",
    "s = classification_report(tst_labels, lr_pred, target_names=keys, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(indices)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "t = plot_tree(clf, filled=True, fontsize=14)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = eli5.explain_weights_df(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_graph_strings = model.get_feature_graph_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "features = defaultdict(list)\n",
    "\n",
    "for target in weights_df.target.unique():\n",
    "    targeted_df = weights_df[weights_df.target == target]\n",
    "    most_important_weights = targeted_df.iloc[:5].feature.str.strip(\"x\").tolist()\n",
    "    for i in most_important_weights:\n",
    "        if i != \"<BIAS>\":\n",
    "            g_nx = feature_graphs[model.inverse_relabel[int(i)]]\n",
    "            if len(g_nx.edges()):\n",
    "                g = feature_graph_strings[model.inverse_relabel[int(i)]]\n",
    "                features[list(keys)[int(target)]].append((g, model.label_vocab.id_to_word[int(target)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"features.json\", \"w+\") as f:\n",
    "    json.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val = split(one_versus_rest, test_size=0.3, random_state=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.label_vocab.id_to_word[int(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_graphs = val.graph.tolist()\n",
    "val_labels = val.one_versus_rest.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_df[\"one_versus_rest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_pickle(\"validation_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "measure_features = []\n",
    "\n",
    "for feat in features:\n",
    "    measure = [feat[0]]\n",
    "    extractor.set_matcher([feat])\n",
    "    false_pos = []\n",
    "    val_predicted = []\n",
    "    for i, g in enumerate(val_graphs):\n",
    "        feats = extractor.matcher.match(g)\n",
    "        label = 0\n",
    "        for feat in feats:\n",
    "            label = feat\n",
    "        if label == 1 and val_labels[i] == 0:\n",
    "            false_pos.append(g)\n",
    "        val_predicted.append(label)\n",
    "    for pcf in precision_recall_fscore_support(val_labels, val_predicted, average=None):\n",
    "        measure.append(pcf[1])\n",
    "    measure.append(false_pos)\n",
    "    \n",
    "    measure_features.append(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(measure_features, columns = ['Feature', 'Precision', 'Recall', \"Fscore\", \"Support\", \"False_positives\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"rules_examine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "Source(to_dot(val_graphs[1537]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.iloc[1537]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "all_features = nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(weights_df.iloc[:10].feature.str.strip(\"x\").tolist()):\n",
    "    node_to_string = {}\n",
    "    g = feature_graphs[model.inverse_relabel[int(t)]]\n",
    "    nodes = []\n",
    "    for n in g.nodes(data=True):\n",
    "        n_post = n[1][\"name\"]+\"_feature\"+str(i)\n",
    "        nodes.append(n_post)\n",
    "        node_to_string[n[0]] = n_post\n",
    "    all_features.add_nodes_from(nodes)\n",
    "    \n",
    "    for e in g.edges(data=True):\n",
    "        all_features.add_edge(node_to_string[e[0]], node_to_string[e[1]], color=e[2][\"color\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "# Create Digraph object\n",
    "dot = to_dot(all_features, integ=True)\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "# Create Digraph object\n",
    "dot = to_dot(feature_graphs[model.inverse_relabel[42]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = []\n",
    "\n",
    "for t in weights_df.iloc[:10].feature.str.strip(\"x\").tolist():\n",
    "    dots.append(feature_graphs[model.inverse_relabel[int(t)]])\n",
    "\n",
    "Source(to_dots(dots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def d_clean(string):\n",
    "    s = string\n",
    "    for c in '\\\\=@-,\\'\".!:;<>/{}[]()#^?':\n",
    "        s = s.replace(c, '_')\n",
    "    s = s.replace('$', '_dollars')\n",
    "    s = s.replace('%', '_percent')\n",
    "    s = s.replace('|', ' ')\n",
    "    s = s.replace('*', ' ')\n",
    "    if s == '#':\n",
    "        s = '_number'\n",
    "    keywords = (\"graph\", \"node\", \"strict\", \"edge\")\n",
    "    if re.match('^[0-9]', s) or s in keywords:\n",
    "        s = \"X\" + s\n",
    "    return s\n",
    "\n",
    "def to_dots(graphs, marked_nodes=set(), integ=False):\n",
    "    lines = [u'digraph finite_state_machine {', '\\tdpi=70;']\n",
    "    # lines.append('\\tordering=out;')\n",
    "    # sorting everything to make the process deterministic\n",
    "    for i, graph in enumerate(graphs):\n",
    "        s = \"subgraph cluster_\" + chr(ord('@')+i+1) + \" {\"\n",
    "        node_lines = []\n",
    "\n",
    "        node_lines.append(s)\n",
    "        node_to_name = {}\n",
    "        for node, n_data in graph.nodes(data=True):\n",
    "            if integ:\n",
    "                d_node = d_clean(str(node))\n",
    "            else:    \n",
    "                d_node = d_clean(n_data[\"name\"])\n",
    "            printname = d_node\n",
    "            node_to_name[node] = printname\n",
    "            if 'expanded' in n_data and n_data['expanded'] and printname in marked_nodes:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=filled, fillcolor=purple];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'expanded' in n_data and n_data['expanded']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'fourlang' in n_data and n_data['fourlang']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\", fillcolor=red];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif 'substituted' in n_data and n_data['substituted']:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                        style=\"filled\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            elif printname in marked_nodes:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\", style=filled, fillcolor=lightblue];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            else:\n",
    "                node_line = u'\\t{0} [shape = circle, label = \"{1}\"];'.format(\n",
    "                    d_node, printname).replace('-', '_')\n",
    "            node_lines.append(node_line)\n",
    "        lines += sorted(node_lines)\n",
    "\n",
    "        edge_lines = []\n",
    "        for u, v, edata in graph.edges(data=True):\n",
    "            if 'color' in edata:\n",
    "                d_node1 = node_to_name[u]\n",
    "                d_node2 = node_to_name[v]\n",
    "                edge_lines.append(\n",
    "                    u'\\t{0} -> {1} [ label = \"{2}\" ];'.format(d_node1, d_node2, edata['color']))\n",
    "\n",
    "        lines += sorted(edge_lines)\n",
    "        lines.append('}')\n",
    "    lines.append('}')\n",
    "    return u'\\n'.join(lines)\n",
    "\n",
    "def to_dot(graph, marked_nodes=set(), integ=False):\n",
    "    lines = [u'digraph finite_state_machine {', '\\tdpi=70;']\n",
    "    # lines.append('\\tordering=out;')\n",
    "    # sorting everything to make the process deterministic\n",
    "    node_lines = []\n",
    "    node_to_name = {}\n",
    "    for node, n_data in graph.nodes(data=True):\n",
    "        if integ:\n",
    "            d_node = d_clean(str(node))\n",
    "        else:    \n",
    "            d_node = d_clean(n_data[\"name\"])\n",
    "        printname = d_node\n",
    "        node_to_name[node] = printname\n",
    "        if 'expanded' in n_data and n_data['expanded'] and printname in marked_nodes:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=filled, fillcolor=purple];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'expanded' in n_data and n_data['expanded']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'fourlang' in n_data and n_data['fourlang']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\", fillcolor=red];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif 'substituted' in n_data and n_data['substituted']:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", \\\n",
    "                    style=\"filled\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        elif printname in marked_nodes:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\", style=filled, fillcolor=lightblue];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        else:\n",
    "            node_line = u'\\t{0} [shape = circle, label = \"{1}\"];'.format(\n",
    "                d_node, printname).replace('-', '_')\n",
    "        node_lines.append(node_line)\n",
    "    lines += sorted(node_lines)\n",
    "\n",
    "    edge_lines = []\n",
    "    for u, v, edata in graph.edges(data=True):\n",
    "        if 'color' in edata:\n",
    "            d_node1 = node_to_name[u]\n",
    "            d_node2 = node_to_name[v]\n",
    "            edge_lines.append(\n",
    "                u'\\t{0} -> {1} [ label = \"{2}\" ];'.format(d_node1, d_node2, edata['color']))\n",
    "\n",
    "    lines += sorted(edge_lines)\n",
    "    lines.append('}')\n",
    "    return u'\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=10)\n",
    "X_kbest = chi2_selector.fit_transform(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(feature_graphs):\n",
    "    if len(g.edges()) != 1:\n",
    "        print(len(g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = to_dot(feature_graphs[2450])\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = to_dot(graphs[0])\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "\n",
    "for l in model.lexgraphs.gen_lex_subgraphs(graphs[0], 1):\n",
    "    print(l)\n",
    "    tests.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = to_dot(tests[3])\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.convert import from_dict_of_dicts as fdd\n",
    "from networkx.convert import to_dict_of_dicts as tdd\n",
    "\n",
    "H_dict = tdd(graphs[0])\n",
    "H_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pickle.dat\", \"rb\") as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in graphs[0].nodes(data=True):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "C = fdd(H_dict,create_using=nx.MultiDiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "\n",
    "outdeg = graphs[7].degree()\n",
    "print(outdeg)\n",
    "\n",
    "to_keep = [n for (n, deg) in outdeg if deg != 0]\n",
    "G = graphs[7].subgraph(to_keep)\n",
    "dot = to_dot(G, integ=False)\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def gen_subgraphs(M, no_edges):\n",
    "    \"\"\"M must be dict of dicts, see networkx.convert.to_dict_of_dicts.\n",
    "    Generates dicts of dicts, use networkx.convert.from_dict_of_dicts\"\"\"\n",
    "    if no_edges == 0:\n",
    "        yield from ({v: {}} for v in M)\n",
    "        return\n",
    "    for s_graph in gen_subgraphs(M, no_edges-1):\n",
    "        yield s_graph\n",
    "        # print('sgraph:', s_graph)\n",
    "        for node in M:\n",
    "            for neighbor, edge in M[node].items():\n",
    "                if node in s_graph and neighbor in s_graph[node]:\n",
    "                    continue\n",
    "                if node not in s_graph and neighbor not in s_graph:\n",
    "                    continue\n",
    "\n",
    "                new_graph = s_graph.copy()\n",
    "                if node not in new_graph:\n",
    "                    new_graph[node] = {neighbor: edge}\n",
    "                else:\n",
    "                    new_graph[node][neighbor] = edge\n",
    "                yield new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgraphs = []\n",
    "for l in model.lexgraphs.gen_lex_subgraphs(G, 1):\n",
    "    if l[1].edges():\n",
    "        sgraphs.append(to_dot(l[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source(sgraphs[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "s = Counter()\n",
    "\n",
    "s[\"banana\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
